"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.insert = exports.injectHTML = void 0;
const moo = __importStar(require("moo"));
/**
 * This isn’t a complete HTML parser by any means; this is a bare-bones lexer
 * that only gives us rudimentary understanding of certain tags (namely, <body>
 * and <head>, as well as comments so they can be ignored). Moo is basically a
 * safer, glorified RegEx parser, so we’re trading off flexibility for
 * performance.
 */
function findHeadAndBody(html) {
    const toLower = (text) => text.trim().replace(/\s/g, '').toLowerCase(); // normalize tags to lowercase, and strip any whitespace
    const lexer = moo.states({
        main: {
            commentStart: { match: /<!--/, push: 'comment' },
            docType: { match: /<![^>]+>/, lineBreaks: true },
            tagOpen: { match: /<\s*[a-zA-Z-]+[^>]*>/, value: toLower },
            tagClose: { match: /<\s*\/[a-zA-Z-]+[^>]*>/, value: toLower },
            ws: { match: /[\s|\t]+/, lineBreaks: true },
            any: { match: /./ },
        },
        comment: {
            commentEnd: { match: /-->/, lineBreaks: true, pop: 1 },
            commentAny: { match: /[^]/, lineBreaks: true },
        },
    });
    return lexer.reset(html);
}
function injectHTML(html, options) {
    let code = html;
    let charOffset = 0;
    const lexer = findHeadAndBody(html);
    // iterate through DOM
    let node = lexer.next();
    while (node) {
        const textToInsert = (node.value === '<head>' && options.headStart) ||
            (node.value === '<body>' && options.bodyStart) ||
            (node.value === '</head>' && options.headEnd) ||
            (node.value === '</body>' && options.bodyEnd);
        if (textToInsert) {
            const tagOffset = node.type === 'tagOpen' ? node.text.length : 0; // if <head> or <body> insert after match; otherwise insert before (at pos)
            let insertion = textToInsert.replace(/^\s*/, '  ');
            if (node.type === 'tagOpen')
                insertion = '\n  ' + insertion;
            if (node.type === 'tagClose')
                insertion = insertion + '\n  ';
            code = insert(code, insertion, node.offset + tagOffset + charOffset); // inject HTML at position
            charOffset += insertion.length;
        }
        node = lexer.next(); // visit next node, until we’re at the end of the document (will return `undefined`)
    }
    return code;
}
exports.injectHTML = injectHTML;
/** Insert any string at certain position */
function insert(text, insertion, pos) {
    return text.substring(0, pos) + insertion + text.substring(pos);
}
exports.insert = insert;
exports.default = injectHTML;
